{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5pYnZEK6FkKIoPkk9Ii9i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascalghanimi/Injury-Prediction-in-Runners/blob/main/CatBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiWE89uWn8sk"
      },
      "outputs": [],
      "source": [
        "# Data extraction for CatBoos\n",
        "import pickle\n",
        "\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "  features = pickle.load(f)\n",
        "\n",
        "with open(\"features_days.pkl\", \"rb\") as f:\n",
        "  features_days = pickle.load(f)\n",
        "\n",
        "with open(\"features_weeks.pkl\", \"rb\") as f:\n",
        "  features_weeks = pickle.load(f)\n",
        "\n",
        "with open(\"features_objective.pkl\", \"rb\") as f:\n",
        "  features_objective = pickle.load(f)\n",
        "\n",
        "with open(\"features_subjective.pkl\", \"rb\") as f:\n",
        "  features_subjective = pickle.load(f)\n",
        "\n",
        "with open(\"labels.pkl\", \"rb\") as f:\n",
        "  labels = pickle.load(f)\n",
        "\n",
        "print(features[0][0]) # greift auf ersten Athleten und erste Reihe zu\n",
        "print(features_days[0][0])\n",
        "print(features_weeks[0])\n",
        "print(labels[0])\n",
        "\n",
        "print(len(features[0][0])) # Anzahl der Features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.vstack([features[athlete_id] for athlete_id in features])\n",
        "X_days = np.vstack([features_days[athlete_id] for athlete_id in features_days])\n",
        "X_weeks = np.vstack([features_weeks[athlete_id] for athlete_id in features_weeks])\n",
        "X_objective = np.vstack([features_objective[athlete_id] for athlete_id in features_objective])\n",
        "X_subjective = np.vstack([features_subjective[athlete_id] for athlete_id in features_subjective])\n",
        "\n",
        "Y = np.hstack([labels[athlete_id] for athlete_id in labels])"
      ],
      "metadata": {
        "id": "bHDWNw0aoCNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_days, X_temp_days, Y_train_days, Y_temp_days = train_test_split(X_days, Y, test_size=0.3, random_state=42)\n",
        "X_val_days, X_test_days, Y_val_days, Y_test_days = train_test_split(X_temp_days, Y_temp_days, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_weeks, X_temp_weeks, Y_train_weeks, Y_temp_weeks = train_test_split(X_weeks, Y, test_size=0.3, random_state=42)\n",
        "X_val_weeks, X_test_weeks, Y_val_weeks, Y_test_weeks = train_test_split(X_temp_weeks, Y_temp_weeks, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_subjective, X_temp_subjective, Y_train_subjective, Y_temp_subjective = train_test_split(X_subjective, Y, test_size=0.3, random_state=42)\n",
        "X_val_subjective, X_test_subjective, Y_val_subjective, Y_test_subjective = train_test_split(X_temp_subjective, Y_temp_subjective, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_objective, X_temp_objective, Y_train_objective, Y_temp_objective = train_test_split(X_objective, Y, test_size=0.3, random_state=42)\n",
        "X_val_objective, X_test_objective, Y_val_objective, Y_test_objective = train_test_split(X_temp_objective, Y_temp_objective, test_size=0.5, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)\n",
        "print(X_train_days.shape, X_val_days.shape, X_test_days.shape)\n",
        "print(X_train_weeks.shape, X_val_weeks.shape, X_test_weeks.shape)\n",
        "print(X_train_subjective.shape, X_val_subjective.shape, X_test_subjective.shape)\n",
        "print(X_train_objective.shape, X_val_objective.shape, X_test_objective.shape)\n",
        "print(Y_train.shape, Y_val.shape, Y_test.shape)"
      ],
      "metadata": {
        "id": "nH0TBgeDoEhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "5uKDfwxzyMuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_batch(X_train, Y_train, batch_size):\n",
        "    injured_indices = np.where(Y_train == 1)[0]\n",
        "    uninjured_indices = np.where(Y_train == 0)[0]\n",
        "\n",
        "    injured_sample = np.random.choice(injured_indices, size=batch_size // 2, replace=True)\n",
        "    uninjured_sample = np.random.choice(uninjured_indices, size=batch_size // 2, replace=True)\n",
        "\n",
        "    selected_indices = np.concatenate([injured_sample, uninjured_sample])\n",
        "    np.random.shuffle(selected_indices)\n",
        "\n",
        "    X_batch = X_train[selected_indices]\n",
        "    Y_batch = Y_train[selected_indices]\n",
        "\n",
        "    return X_batch, Y_batch"
      ],
      "metadata": {
        "id": "2_JJWmBVw17r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
        "\n",
        "def catboost_objective(trial):\n",
        "    params = {\n",
        "        'iterations': trial.suggest_int('iterations', 500, 2000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10, log=True),\n",
        "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
        "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
        "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
        "        'score_function': trial.suggest_categorical('score_function', ['L2', 'Cosine', 'NewtonL2']),\n",
        "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 150),\n",
        "        'boosting_type': 'Plain'  # Wichtig gegen Target Leakage\n",
        "    }\n",
        "\n",
        "    # Batch Sampling\n",
        "    X_batch, Y_batch = get_training_batch(X_train, Y_train, 2048)\n",
        "\n",
        "    model = CatBoostClassifier(\n",
        "        **params,\n",
        "        verbose=False,\n",
        "        auto_class_weights='Balanced',\n",
        "        task_type=\"GPU\"\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_batch, Y_batch,\n",
        "        eval_set=(X_val, Y_val),\n",
        "        use_best_model=True\n",
        "    )\n",
        "\n",
        "    # Validation AUC\n",
        "    val_proba = model.predict_proba(X_val)[:, 1]\n",
        "    return roc_auc_score(Y_val, val_proba)\n",
        "\n",
        "# Start optuna study\n",
        "catboost_study = optuna.create_study(direction='maximize')\n",
        "catboost_study.optimize(catboost_objective, n_trials=100) # 100 trials\n",
        "\n",
        "# Show best parameters\n",
        "print(\"Beste CatBoost-Parameters:\", catboost_study.best_params)"
      ],
      "metadata": {
        "id": "D8lHTcv7xF7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "def train (X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
        "  warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
        "\n",
        "  params = catboost_study.best_params\n",
        "  params.update({\n",
        "      'auto_class_weights': 'Balanced',\n",
        "      'verbose': False,\n",
        "      'boosting_type': 'Plain'\n",
        "  })\n",
        "\n",
        "\n",
        "\n",
        "  num_models = 9\n",
        "  models = []\n",
        "  batch_size = 2048\n",
        "\n",
        "  for model_idx in range(num_models):\n",
        "    X_batch, Y_batch = get_training_batch(X_train, Y_train, batch_size)\n",
        "\n",
        "    model = CatBoostClassifier(**params, task_type=\"GPU\")\n",
        "    model.fit(\n",
        "    X_batch, Y_batch,\n",
        "    eval_set=(X_val, Y_val),\n",
        "    verbose=False,\n",
        "    use_best_model=True,\n",
        "    )\n",
        "\n",
        "    Y_test_pred = model.predict_proba(X_test)[:, 1]\n",
        "    test_auc = roc_auc_score(Y_test, Y_test_pred)\n",
        "    print(f\"Model {model_idx + 1} Test AUC: {test_auc}\")\n",
        "\n",
        "    models.append(model)\n",
        "\n",
        "\n",
        "  calibrated_models = [CalibratedClassifierCV(m, method=\"sigmoid\", cv=\"prefit\").fit(X_val, Y_val) for m in models]\n",
        "\n",
        "  def ensemble_predict(models, X):\n",
        "    test_probas = np.stack([m.predict_proba(X)[:, 1] for m in models])\n",
        "    return np.mean(test_probas, axis=0)\n",
        "\n",
        "  Y_proba_test = ensemble_predict(calibrated_models, X_test)\n",
        "  test_auc_score = roc_auc_score(Y_test, Y_proba_test)\n",
        "  print(\"Ensemble Test AUC:\", test_auc_score)\n",
        "\n",
        "  return calibrated_models, test_auc_score"
      ],
      "metadata": {
        "id": "dvoQejx2oGDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with all features (days and weeks combined)\n",
        "cb_models, _ = train(X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ],
      "metadata": {
        "id": "BBCfUUuSy-jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with days data\n",
        "cb_models_days, _ = train(X_train_days, Y_train_days, X_val_days, Y_val_days, X_test_days, Y_test_days)"
      ],
      "metadata": {
        "id": "8ZpoZR70zA8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training mit weeks data\n",
        "cb_models_weeks, _ = train(X_train_weeks, Y_train_weeks, X_val_weeks, Y_val_weeks, X_test_weeks, Y_test_weeks)"
      ],
      "metadata": {
        "id": "nFbnDpSzzCEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with objective data\n",
        "cb_models_objective, _ = train(X_train_objective, Y_train_objective, X_val_objective, Y_val_objective, X_test_objective, Y_test_objective)"
      ],
      "metadata": {
        "id": "7eWiI-GKzDKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training mit subjective data\n",
        "cb_models_subjective, _ = train(X_train_subjective, Y_train_subjective, X_val_subjective, Y_val_subjective, X_test_subjective, Y_test_subjective)"
      ],
      "metadata": {
        "id": "WZE09ixLzEKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amount_of_trainings = 10\n",
        "all_auc_scores = []\n",
        "auc_scores_days = []\n",
        "auc_scores_weeks = []\n",
        "auc_scores_objective = []\n",
        "auc_scores_subjective = []\n",
        "\n",
        "def calculate_average_auc_over_10_rounds(train_fn, auc_scores_array):\n",
        "  for training in range(amount_of_trainings):\n",
        "    _, auc = train_fn()\n",
        "    auc_scores_array.append(auc)\n",
        "  mean_auc_score = np.mean(auc_scores_array)\n",
        "  std_auc_score = np.std(auc_scores_array)\n",
        "  print(f\"Mean AUC Score: {mean_auc_score}\")\n",
        "  print(f\"Standard Deviation of AUC Scores: {std_auc_score}\")\n",
        "\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train, Y_train, X_val, Y_val, X_test, Y_test), all_auc_scores)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_days, Y_train_days, X_val_days, Y_val_days, X_test_days, Y_test_days), auc_scores_days)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_weeks, Y_train_weeks, X_val_weeks, Y_val_weeks, X_test_weeks, Y_test_weeks), auc_scores_weeks)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_objective, Y_train_objective, X_val_objective, Y_val_objective, X_test_objective, Y_test_objective), auc_scores_objective)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_subjective, Y_train_subjective, X_val_subjective, Y_val_subjective, X_test_subjective, Y_test_subjective), auc_scores_subjective)"
      ],
      "metadata": {
        "id": "yAfYFFMyyfPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Boxplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.boxplot(\n",
        "    [all_auc_scores, auc_scores_days, auc_scores_weeks, auc_scores_objective, auc_scores_subjective],\n",
        "    labels=[\"All Features\", \"Days\", \"Weeks\", \"Objective\", \"Subjective\"],\n",
        "    patch_artist=True\n",
        ")\n",
        "plt.ylabel(\"AUC Score\")\n",
        "plt.title(\"Vergleich der AUC Scores über verschiedene Feature-Sets\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Mean\n",
        "mean_auc_scores = {\n",
        "    \"All Features\": np.mean(all_auc_scores),\n",
        "    \"Days\": np.mean(auc_scores_days),\n",
        "    \"Weeks\": np.mean(auc_scores_weeks),\n",
        "    \"Objective\": np.mean(auc_scores_objective),\n",
        "    \"Subjective\": np.mean(auc_scores_subjective),\n",
        "}\n",
        "\n",
        "# Diagrams\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(mean_auc_scores.keys(), mean_auc_scores.values(), color=[\"blue\", \"green\", \"orange\", \"red\", \"purple\"], alpha=0.7)\n",
        "plt.ylabel(\"Mean AUC Score\")\n",
        "plt.title(\"Mittlere AUC Scores für verschiedene Feature-Sets\")\n",
        "plt.ylim(min(mean_auc_scores.values()) - 0.01, max(mean_auc_scores.values()) + 0.01)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "\n",
        "for i, v in enumerate(mean_auc_scores.values()):\n",
        "    plt.text(i, v + 0.002, f\"{v:.4f}\", ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kkgLHw0kEOFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single model export (only all features since it has the best probabilities overall)\n",
        "joblib.dump(cb_models, 'cb_models.pkl')"
      ],
      "metadata": {
        "id": "xBht3bKoVP6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model export for Ensemble prediction later\n",
        "import joblib\n",
        "\n",
        "joblib.dump(cb_models, 'cb_models.pkl')\n",
        "joblib.dump(cb_models_days, 'cb_models_days.pkl')\n",
        "joblib.dump(cb_models_weeks, 'cb_models_weeks.pkl')\n",
        "joblib.dump(cb_models_objective, 'cb_models_objective.pkl')\n",
        "joblib.dump(cb_models_subjective, 'cb_models_subjective.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_fLSsmvAj1p",
        "outputId": "19e68df0-db23-402f-9d1f-a8c40ae1f0b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cb_models_subjective.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}