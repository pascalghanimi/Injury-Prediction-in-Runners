{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxMrF3iCgb5yx60WZKBFaA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascalghanimi/Injury-Prediction-in-Runners/blob/main/LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNa6ERryVcbS"
      },
      "outputs": [],
      "source": [
        "# Data extraction for LightGBM\n",
        "import pickle\n",
        "\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "  features = pickle.load(f)\n",
        "\n",
        "with open(\"features_days.pkl\", \"rb\") as f:\n",
        "  features_days = pickle.load(f)\n",
        "\n",
        "with open(\"features_weeks.pkl\", \"rb\") as f:\n",
        "  features_weeks = pickle.load(f)\n",
        "\n",
        "with open(\"features_objective.pkl\", \"rb\") as f:\n",
        "  features_objective = pickle.load(f)\n",
        "\n",
        "with open(\"features_subjective.pkl\", \"rb\") as f:\n",
        "  features_subjective = pickle.load(f)\n",
        "\n",
        "with open(\"labels.pkl\", \"rb\") as f:\n",
        "  labels = pickle.load(f)\n",
        "\n",
        "print(features[0][0]) # first atlete first row\n",
        "print(features_days[0][0])\n",
        "print(features_weeks[0])\n",
        "print(labels[0])\n",
        "\n",
        "print(len(features[0][0])) # total amount of features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.vstack([features[athlete_id] for athlete_id in features])\n",
        "X_days = np.vstack([features_days[athlete_id] for athlete_id in features_days])\n",
        "X_weeks = np.vstack([features_weeks[athlete_id] for athlete_id in features_weeks])\n",
        "X_objective = np.vstack([features_objective[athlete_id] for athlete_id in features_objective])\n",
        "X_subjective = np.vstack([features_subjective[athlete_id] for athlete_id in features_subjective])\n",
        "\n",
        "Y = np.hstack([labels[athlete_id] for athlete_id in labels])\n"
      ],
      "metadata": {
        "id": "ck4_HbkzVfUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_days, X_temp_days, Y_train_days, Y_temp_days = train_test_split(X_days, Y, test_size=0.3, random_state=42)\n",
        "X_val_days, X_test_days, Y_val_days, Y_test_days = train_test_split(X_temp_days, Y_temp_days, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_weeks, X_temp_weeks, Y_train_weeks, Y_temp_weeks = train_test_split(X_weeks, Y, test_size=0.3, random_state=42)\n",
        "X_val_weeks, X_test_weeks, Y_val_weeks, Y_test_weeks = train_test_split(X_temp_weeks, Y_temp_weeks, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_subjective, X_temp_subjective, Y_train_subjective, Y_temp_subjective = train_test_split(X_subjective, Y, test_size=0.3, random_state=42)\n",
        "X_val_subjective, X_test_subjective, Y_val_subjective, Y_test_subjective = train_test_split(X_temp_subjective, Y_temp_subjective, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_objective, X_temp_objective, Y_train_objective, Y_temp_objective = train_test_split(X_objective, Y, test_size=0.3, random_state=42)\n",
        "X_val_objective, X_test_objective, Y_val_objective, Y_test_objective = train_test_split(X_temp_objective, Y_temp_objective, test_size=0.5, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)\n",
        "print(X_train_days.shape, X_val_days.shape, X_test_days.shape)\n",
        "print(X_train_weeks.shape, X_val_weeks.shape, X_test_weeks.shape)\n",
        "print(X_train_subjective.shape, X_val_subjective.shape, X_test_subjective.shape)\n",
        "print(X_train_objective.shape, X_val_objective.shape, X_test_objective.shape)\n",
        "print(Y_train.shape, Y_val.shape, Y_test.shape)\n"
      ],
      "metadata": {
        "id": "Nf3lM_wGVgnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "uvQxpjPWbGtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_batch(X_train, Y_train, batch_size):\n",
        "    injured_indices = np.where(Y_train == 1)[0]\n",
        "    uninjured_indices = np.where(Y_train == 0)[0]\n",
        "\n",
        "    injured_sample = np.random.choice(injured_indices, size=batch_size//2, replace=True)\n",
        "    uninjured_sample = np.random.choice(uninjured_indices, size=batch_size//2, replace=True)\n",
        "\n",
        "    selected_indices = np.concatenate([injured_sample, uninjured_sample])\n",
        "    np.random.shuffle(selected_indices)\n",
        "\n",
        "    X_batch = X_train[selected_indices]\n",
        "    Y_batch = Y_train[selected_indices]\n",
        "\n",
        "    return X_batch, Y_batch"
      ],
      "metadata": {
        "id": "iNKp0Jmxz5dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
        "\n",
        "def lightgbm_objective(trial):\n",
        "    params = {\n",
        "        \"objective\": \"binary\",\n",
        "        \"metric\": \"auc\",\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 7, 255),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
        "        \"reg_alpha\": trial.suggest_float(\"lambda_l1\", 0.0, 5.0),\n",
        "        \"reg_lambda\": trial.suggest_float(\"lambda_l2\", 0.0, 5.0),\n",
        "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"gbdt\", \"dart\", \"goss\"]),\n",
        "        \"verbose\": -1\n",
        "    }\n",
        "\n",
        "    # Batch Sampling\n",
        "    X_batch, Y_batch = get_training_batch(X_train, Y_train, 4096)\n",
        "\n",
        "    model = lgb.LGBMClassifier(**params)\n",
        "    model.fit(\n",
        "        X_batch, Y_batch,\n",
        "        eval_set=[(X_val, Y_val)],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
        "    )\n",
        "\n",
        "    # Validation AUC\n",
        "    val_proba = model.predict_proba(X_val)[:, 1]\n",
        "    return roc_auc_score(Y_val, val_proba)\n",
        "\n",
        "# Optuna-Studie starten\n",
        "lgb_study = optuna.create_study(direction=\"maximize\")\n",
        "lgb_study.optimize(lightgbm_objective, n_trials=100) # 100 trials\n",
        "\n",
        "print(\"Best LightGBM-parameters:\", lgb_study.best_params)"
      ],
      "metadata": {
        "id": "fl5q1NmgpDRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import warnings\n",
        "\n",
        "def train(X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
        "  warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
        "\n",
        "  params = {**lgb_study.best_params}  # Erst in ein normales Dict umwandeln\n",
        "  params.update({\n",
        "      \"objective\": \"binary\",\n",
        "      \"metric\": \"auc\",\n",
        "      \"verbose\": -1\n",
        "  })\n",
        "\n",
        "\n",
        "  num_models = 9\n",
        "  models = []\n",
        "  batch_size = 4096\n",
        "\n",
        "  for model_idx in range(num_models):\n",
        "    X_batch, Y_batch = get_training_batch(X_train, Y_train, batch_size)\n",
        "    model = lgb.LGBMClassifier(**params)\n",
        "    model.fit(X_batch, Y_batch, eval_set=[(X_val, Y_val)])\n",
        "    Y_pred_test = model.predict_proba(X_test)[:, 1]\n",
        "    test_auc = roc_auc_score(Y_test, Y_pred_test)\n",
        "\n",
        "    print(f\"\\nLightGBM Modell {model_idx + 1} Results:\")\n",
        "    print(f\"Test-AUC: {test_auc:.4f}\")\n",
        "    models.append(model)\n",
        "\n",
        "  calibrated_models = [\n",
        "          CalibratedClassifierCV(m, method='sigmoid', cv=\"prefit\").fit(X_val, Y_val) for m in models\n",
        "  ]\n",
        "\n",
        "  def ensemble_predict(models, X):\n",
        "    test_probas = np.stack([m.predict_proba(X)[:, 1] for m in models])\n",
        "    return np.mean(test_probas, axis=0)\n",
        "\n",
        "  Y_probab_test = ensemble_predict(calibrated_models, X_test)\n",
        "  test_auc = roc_auc_score(Y_test, Y_probab_test)\n",
        "\n",
        "  print(f\"Test-AUC of LightGBM Ensembles: {test_auc:.4f}\")\n",
        "\n",
        "  return calibrated_models, test_auc"
      ],
      "metadata": {
        "id": "5G9aRN4PVo9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with all features (weeks and days combined)\n",
        "lgbm_models, _ = train(X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ],
      "metadata": {
        "id": "LGUYXlk1bG7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with days data\n",
        "lgbm_models_days, _ = train(X_train_days, Y_train_days, X_val_days, Y_val_days, X_test_days, Y_test_days)"
      ],
      "metadata": {
        "id": "DlKBBc31bI5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with weeks data\n",
        "lgbm_models_weeks, _ = train(X_train_weeks, Y_train_weeks, X_val_weeks, Y_val_weeks, X_test_weeks, Y_test_weeks)"
      ],
      "metadata": {
        "id": "WXJayLfvbKbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with objective data\n",
        "lgbm_models_objective, _ = train(X_train_objective, Y_train_objective, X_val_objective, Y_val_objective, X_test_objective, Y_test_objective)"
      ],
      "metadata": {
        "id": "dQy5DkOxbLot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with subjective data\n",
        "lgbm_models_subjective, _ = train(X_train_subjective, Y_train_subjective, X_val_subjective, Y_val_subjective, X_test_subjective, Y_test_subjective)"
      ],
      "metadata": {
        "id": "I4JT8i20bM1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amount_of_trainings = 10\n",
        "all_auc_scores = []\n",
        "auc_scores_days = []\n",
        "auc_scores_weeks = []\n",
        "auc_scores_objective = []\n",
        "auc_scores_subjective = []\n",
        "\n",
        "def calculate_average_auc_over_10_rounds(train_fn, auc_scores_array):\n",
        "  for training in range(amount_of_trainings):\n",
        "    _, auc = train_fn()\n",
        "    auc_scores_array.append(auc)\n",
        "  mean_auc_score = np.mean(auc_scores_array)\n",
        "  std_auc_score = np.std(auc_scores_array)\n",
        "  print(f\"Mean AUC Score: {mean_auc_score}\")\n",
        "  print(f\"Standard Deviation of AUC Scores: {std_auc_score}\")\n",
        "\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train, Y_train, X_val, Y_val, X_test, Y_test), all_auc_scores)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_days, Y_train_days, X_val_days, Y_val_days, X_test_days, Y_test_days), auc_scores_days)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_weeks, Y_train_weeks, X_val_weeks, Y_val_weeks, X_test_weeks, Y_test_weeks), auc_scores_weeks)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_objective, Y_train_objective, X_val_objective, Y_val_objective, X_test_objective, Y_test_objective), auc_scores_objective)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_subjective, Y_train_subjective, X_val_subjective, Y_val_subjective, X_test_subjective, Y_test_subjective), auc_scores_subjective)"
      ],
      "metadata": {
        "id": "gwhi8bhG0BQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Boxplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.boxplot(\n",
        "    [all_auc_scores, auc_scores_days, auc_scores_weeks, auc_scores_objective, auc_scores_subjective],\n",
        "    labels=[\"All Features\", \"Days\", \"Weeks\", \"Objective\", \"Subjective\"],\n",
        "    patch_artist=True\n",
        ")\n",
        "plt.ylabel(\"AUC Score\")\n",
        "plt.title(\"Vergleich der AUC Scores über verschiedene Feature-Sets\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Mean\n",
        "mean_auc_scores = {\n",
        "    \"All Features\": np.mean(all_auc_scores),\n",
        "    \"Days\": np.mean(auc_scores_days),\n",
        "    \"Weeks\": np.mean(auc_scores_weeks),\n",
        "    \"Objective\": np.mean(auc_scores_objective),\n",
        "    \"Subjective\": np.mean(auc_scores_subjective),\n",
        "}\n",
        "\n",
        "# Diagrams\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(mean_auc_scores.keys(), mean_auc_scores.values(), color=[\"blue\", \"green\", \"orange\", \"red\", \"purple\"], alpha=0.7)\n",
        "plt.ylabel(\"Mean AUC Score\")\n",
        "plt.title(\"Mittlere AUC Scores für verschiedene Feature-Sets\")\n",
        "plt.ylim(min(mean_auc_scores.values()) - 0.01, max(mean_auc_scores.values()) + 0.01)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "\n",
        "for i, v in enumerate(mean_auc_scores.values()):\n",
        "    plt.text(i, v + 0.002, f\"{v:.4f}\", ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AJT64nqNERWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single model export (only all features since it has the best probabilities overall)\n",
        "joblib.dump(lgbm_models, 'lgbm_models.pkl')"
      ],
      "metadata": {
        "id": "4XyPqp3RVWxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model export for Ensemble prediction later\n",
        "import joblib\n",
        "\n",
        "joblib.dump(lgbm_models, 'lgbm_models.pkl')\n",
        "joblib.dump(lgbm_models_days, 'lgbm_models_days.pkl')\n",
        "joblib.dump(lgbm_models_weeks, 'lgbm_models_weeks.pkl')\n",
        "joblib.dump(lgbm_models_objective, 'lgbm_models_objective.pkl')\n",
        "joblib.dump(lgbm_models_subjective, 'lgbm_models_subjective.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJzydf4wBpys",
        "outputId": "d6f7df72-ee72-45af-949b-65a2698498d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lgbm_models_subjective.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}