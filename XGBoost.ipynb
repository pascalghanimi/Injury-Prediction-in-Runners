{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLT19NIQqe6RmB6CM4Gj64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascalghanimi/Injury-Prediction-in-Runners/blob/main/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0NDZyyn2tbh",
        "outputId": "237db932-85a6-4366-f6c9-7d7498ae2ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  1.00000000e+00  8.00000000e-02\n",
            "  0.00000000e+00  1.80000000e-01  1.00000000e+00  1.15000000e+01\n",
            "  5.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  1.00000000e-01  0.00000000e+00  1.80000000e-01\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.00000000e-02\n",
            " -1.00000000e-02 -1.00000000e-02  1.00000000e+00  4.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  1.00000000e-01  0.00000000e+00  1.70000000e-01\n",
            "  1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  1.25000000e+00  9.00000000e-02\n",
            "  0.00000000e+00  1.70000000e-01  1.00000000e+00  4.90000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  9.00000000e-01  0.00000000e+00\n",
            "  0.00000000e+00  1.00000000e-01  0.00000000e+00  1.70000000e-01\n",
            "  1.00000000e+00  1.45000000e+01  4.50000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.00000000e-02\n",
            "  0.00000000e+00  1.70000000e-01  6.00000000e+00  1.00000000e+00\n",
            "  3.49000000e+01  1.45000000e+01  1.04000000e+01  0.00000000e+00\n",
            "  2.00000000e+00  9.50000000e+00  5.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  2.25000000e+00  0.00000000e+00  9.00000000e-02\n",
            "  8.00000000e-02  1.00000000e-01  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  1.70000000e-01  1.70000000e-01  1.80000000e-01\n",
            "  7.00000000e+00  0.00000000e+00  3.77000000e+01  1.18000000e+01\n",
            "  1.19000000e+01  0.00000000e+00  3.00000000e+00  1.19000000e+01\n",
            "  5.80000000e+00  0.00000000e+00  0.00000000e+00  1.67000000e+00\n",
            "  1.00000000e+00  9.00000000e-02  8.00000000e-02  1.00000000e-01\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.70000000e-01\n",
            "  1.60000000e-01  1.80000000e-01  4.00000000e+00  3.00000000e+00\n",
            "  3.70000000e+00  3.70000000e+00  7.00000000e-01  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  2.67000000e+00  0.00000000e+00  9.00000000e-02\n",
            "  8.00000000e-02  9.00000000e-02  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  1.80000000e-01  1.70000000e-01  1.80000000e-01\n",
            "  9.25729418e-01  9.43242988e+00  1.01891864e+01]\n",
            "Shape X_train_injured (402, 139)\n",
            "Size X_train_injured 55878\n",
            "Shape X_train_injured_weeks (402, 69)\n",
            "Shape X_train_injured_days (402, 70)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "all_data = np.load(\"all_data.npz\")\n",
        "\n",
        "X_train_injured = all_data[\"X_train_injured\"]\n",
        "X_val_injured = all_data[\"X_val_injured\"]\n",
        "X_test_injured = all_data[\"X_test_injured\"]\n",
        "Y_train_labels_injured = all_data[\"Y_train_labels_injured\"]\n",
        "Y_val_labels_injured = all_data[\"Y_val_labels_injured\"]\n",
        "Y_test_labels_injured = all_data[\"Y_test_labels_injured\"]\n",
        "X_train_uninjured = all_data[\"X_train_uninjured\"]\n",
        "X_val_uninjured = all_data[\"X_val_uninjured\"]\n",
        "X_test_uninjured = all_data[\"X_test_uninjured\"]\n",
        "Y_train_labels_uninjured = all_data[\"Y_train_labels_uninjured\"]\n",
        "Y_val_labels_uninjured = all_data[\"Y_val_labels_uninjured\"]\n",
        "Y_test_labels_uninjured = all_data[\"Y_test_labels_uninjured\"]\n",
        "\n",
        "\n",
        "weeks_data = np.load(\"weeks_data.npz\")\n",
        "\n",
        "X_train_injured_weeks = weeks_data[\"X_train_injured_weeks\"]\n",
        "X_val_injured_weeks = weeks_data[\"X_val_injured_weeks\"]\n",
        "X_test_injured_weeks = weeks_data[\"X_test_injured_weeks\"]\n",
        "Y_train_labels_injured_weeks = weeks_data[\"Y_train_labels_injured_weeks\"]\n",
        "Y_val_labels_injured_weeks = weeks_data[\"Y_val_labels_injured_weeks\"]\n",
        "Y_test_labels_injured_weeks = weeks_data[\"Y_test_labels_injured_weeks\"]\n",
        "X_train_uninjured_weeks = weeks_data[\"X_train_uninjured_weeks\"]\n",
        "X_val_uninjured_weeks = weeks_data[\"X_val_uninjured_weeks\"]\n",
        "X_test_uninjured_weeks = weeks_data[\"X_test_uninjured_weeks\"]\n",
        "Y_train_labels_uninjured_weeks = weeks_data[\"Y_train_labels_uninjured_weeks\"]\n",
        "Y_val_labels_uninjured_weeks = weeks_data[\"Y_val_labels_uninjured_weeks\"]\n",
        "Y_test_labels_uninjured_weeks = weeks_data[\"Y_test_labels_uninjured_weeks\"]\n",
        "\n",
        "\n",
        "days_data = np.load(\"days_data.npz\")\n",
        "\n",
        "X_train_injured_days = days_data[\"X_train_injured_days\"]\n",
        "X_val_injured_days = days_data[\"X_val_injured_days\"]\n",
        "X_test_injured_days = days_data[\"X_test_injured_days\"]\n",
        "Y_train_labels_injured_days = days_data[\"Y_train_labels_injured_days\"]\n",
        "Y_val_labels_injured_days = days_data[\"Y_val_labels_injured_days\"]\n",
        "Y_test_labels_injured_days = days_data[\"Y_test_labels_injured_days\"]\n",
        "X_train_uninjured_days = days_data[\"X_train_uninjured_days\"]\n",
        "X_val_uninjured_days = days_data[\"X_val_uninjured_days\"]\n",
        "X_test_uninjured_days = days_data[\"X_test_uninjured_days\"]\n",
        "Y_train_labels_uninjured_days = days_data[\"Y_train_labels_uninjured_days\"]\n",
        "Y_val_labels_uninjured_days = days_data[\"Y_val_labels_uninjured_days\"]\n",
        "Y_test_labels_uninjured_days = days_data[\"Y_test_labels_uninjured_days\"]\n",
        "\n",
        "\n",
        "print(X_train_injured[0])\n",
        "print(\"Shape X_train_injured\", X_train_injured.shape)\n",
        "print(\"Size X_train_injured\", X_train_injured.size)\n",
        "\n",
        "print(\"Shape X_train_injured_weeks\", X_train_injured_weeks.shape)\n",
        "print(\"Shape X_train_injured_days\", X_train_injured_days.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validierungs- und Testdatensatz vorbereiten und mischen\n",
        "X_val = np.concatenate([X_val_injured, X_val_uninjured])\n",
        "Y_val = np.concatenate([Y_val_labels_injured, Y_val_labels_uninjured])\n",
        "val_indices = np.arange(len(Y_val))\n",
        "np.random.shuffle(val_indices)\n",
        "X_val = X_val[val_indices]\n",
        "Y_val = Y_val[val_indices]\n",
        "\n",
        "X_test = np.concatenate([X_test_injured, X_test_uninjured])\n",
        "Y_test = np.concatenate([Y_test_labels_injured, Y_test_labels_uninjured])\n",
        "test_indices = np.arange(len(Y_test))\n",
        "np.random.shuffle(test_indices)\n",
        "X_test = X_test[test_indices]\n",
        "Y_test = Y_test[test_indices]"
      ],
      "metadata": {
        "id": "bWJtfMz8zThT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Daten vorbereiten und mischen\n",
        "X_val = np.concatenate([X_val_injured, X_val_uninjured])\n",
        "Y_val = np.concatenate([Y_val_labels_injured, Y_val_labels_uninjured])\n",
        "val_indices = np.arange(len(Y_val))\n",
        "np.random.shuffle(val_indices)\n",
        "X_val = X_val[val_indices]\n",
        "Y_val = Y_val[val_indices]\n",
        "\n",
        "X_test = np.concatenate([X_test_injured, X_test_uninjured])\n",
        "Y_test = np.concatenate([Y_test_labels_injured, Y_test_labels_uninjured])\n",
        "test_indices = np.arange(len(Y_test))\n",
        "np.random.shuffle(test_indices)\n",
        "X_test = X_test[test_indices]\n",
        "Y_test = Y_test[test_indices]\n",
        "\n",
        "# Scaler GLOBAL auf allen Trainingsdaten initialisieren\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(np.concatenate([X_train_injured, X_train_uninjured]))\n",
        "\n",
        "# Funktion f√ºr dynamische Batcherstellung\n",
        "def get_training_batch(\n",
        "    X_train_injured,\n",
        "    Y_train_labels_injured,\n",
        "    X_train_uninjured,\n",
        "    Y_train_labels_uninjured,\n",
        "    batch_size\n",
        "):\n",
        "    injured_indices = np.random.choice(len(X_train_injured), batch_size // 2, replace=True)\n",
        "    uninjured_indices = np.random.choice(len(X_train_uninjured), batch_size // 2, replace=True)\n",
        "\n",
        "    X_batch = np.concatenate([\n",
        "        X_train_injured[injured_indices],\n",
        "        X_train_uninjured[uninjured_indices]\n",
        "    ])\n",
        "    Y_batch = np.concatenate([\n",
        "        Y_train_labels_injured[injured_indices],\n",
        "        Y_train_labels_uninjured[uninjured_indices]\n",
        "    ])\n",
        "\n",
        "    # Scaler NUR transformieren (nicht fit_transform!)\n",
        "    X_batch = scaler.transform(X_batch)\n",
        "\n",
        "    return X_batch, Y_batch\n",
        "\n",
        "# Modelparameter\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"eta\": 0.05,\n",
        "    \"max_depth\": 3,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"n_estimators\": 512,\n",
        "    \"lambda\": 1.0,\n",
        "    \"alpha\": 0.5\n",
        "}\n",
        "\n",
        "# Trainingskonfiguration\n",
        "num_models = 9\n",
        "models = []\n",
        "num_epochs = 20\n",
        "batch_size = 256\n",
        "\n",
        "# Validierungs- und Testdaten skalieren (einmalig)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Training\n",
        "for model_idx in range(num_models):\n",
        "    print(f\"\\nTraining Modell {model_idx + 1}/{num_models}\")\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "    highest_auc = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # NEUER Batch in jeder Epoche\n",
        "        X_batch, Y_batch = get_training_batch(\n",
        "            X_train_injured,\n",
        "            Y_train_labels_injured,\n",
        "            X_train_uninjured,\n",
        "            Y_train_labels_uninjured,\n",
        "            batch_size\n",
        "        )\n",
        "\n",
        "        model.fit(X_batch, Y_batch, eval_set=[(X_val_scaled, Y_val)], verbose=False)\n",
        "        Y_pred_val = model.predict_proba(X_val_scaled)[:, 1]\n",
        "        auc = roc_auc_score(Y_val, Y_pred_val)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} | Val-AUC: {auc:.4f}\")\n",
        "\n",
        "        if auc > highest_auc:\n",
        "            highest_auc = auc\n",
        "\n",
        "    # Finale Testbewertung\n",
        "    Y_pred_test = model.predict_proba(X_test_scaled)[:, 1]\n",
        "    test_auc = roc_auc_score(Y_test, Y_pred_test)\n",
        "    print(f\"\\nModell {model_idx + 1} Ergebnisse:\")\n",
        "    print(f\"Beste Val-AUC: {highest_auc:.4f}\")\n",
        "    print(f\"Test-AUC: {test_auc:.4f}\")\n",
        "    models.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DSg1t4E7wRI_",
        "outputId": "144dae19-56cb-4946-9eb6-af0464ce3605"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Modell 1/9\n",
            "Epoch 1/20 | Val-AUC: 0.7386\n",
            "Epoch 2/20 | Val-AUC: 0.6105\n",
            "Epoch 3/20 | Val-AUC: 0.5395\n",
            "Epoch 4/20 | Val-AUC: 0.7215\n",
            "Epoch 5/20 | Val-AUC: 0.4650\n",
            "Epoch 6/20 | Val-AUC: 0.6060\n",
            "Epoch 7/20 | Val-AUC: 0.5559\n",
            "Epoch 8/20 | Val-AUC: 0.4515\n",
            "Epoch 9/20 | Val-AUC: 0.7136\n",
            "Epoch 10/20 | Val-AUC: 0.4399\n",
            "Epoch 11/20 | Val-AUC: 0.5503\n",
            "Epoch 12/20 | Val-AUC: 0.6202\n",
            "Epoch 13/20 | Val-AUC: 0.6423\n",
            "Epoch 14/20 | Val-AUC: 0.6472\n",
            "Epoch 15/20 | Val-AUC: 0.6297\n",
            "Epoch 16/20 | Val-AUC: 0.6912\n",
            "Epoch 17/20 | Val-AUC: 0.4565\n",
            "Epoch 18/20 | Val-AUC: 0.6293\n",
            "Epoch 19/20 | Val-AUC: 0.6165\n",
            "Epoch 20/20 | Val-AUC: 0.5661\n",
            "\n",
            "Modell 1 Ergebnisse:\n",
            "Beste Val-AUC: 0.7386\n",
            "Test-AUC: 0.5534\n",
            "\n",
            "Training Modell 2/9\n",
            "Epoch 1/20 | Val-AUC: 0.8125\n",
            "Epoch 2/20 | Val-AUC: 0.3995\n",
            "Epoch 3/20 | Val-AUC: 0.5914\n",
            "Epoch 4/20 | Val-AUC: 0.4805\n",
            "Epoch 5/20 | Val-AUC: 0.3957\n",
            "Epoch 6/20 | Val-AUC: 0.7107\n",
            "Epoch 7/20 | Val-AUC: 0.5334\n",
            "Epoch 8/20 | Val-AUC: 0.6948\n",
            "Epoch 9/20 | Val-AUC: 0.5707\n",
            "Epoch 10/20 | Val-AUC: 0.5722\n",
            "Epoch 11/20 | Val-AUC: 0.6715\n",
            "Epoch 12/20 | Val-AUC: 0.6996\n",
            "Epoch 13/20 | Val-AUC: 0.4726\n",
            "Epoch 14/20 | Val-AUC: 0.8435\n",
            "Epoch 15/20 | Val-AUC: 0.4194\n",
            "Epoch 16/20 | Val-AUC: 0.6619\n",
            "Epoch 17/20 | Val-AUC: 0.6479\n",
            "Epoch 18/20 | Val-AUC: 0.6417\n",
            "Epoch 19/20 | Val-AUC: 0.5746\n",
            "Epoch 20/20 | Val-AUC: 0.7948\n",
            "\n",
            "Modell 2 Ergebnisse:\n",
            "Beste Val-AUC: 0.8435\n",
            "Test-AUC: 0.7673\n",
            "\n",
            "Training Modell 3/9\n",
            "Epoch 1/20 | Val-AUC: 0.5585\n",
            "Epoch 2/20 | Val-AUC: 0.6217\n",
            "Epoch 3/20 | Val-AUC: 0.5568\n",
            "Epoch 4/20 | Val-AUC: 0.3239\n",
            "Epoch 5/20 | Val-AUC: 0.6121\n",
            "Epoch 6/20 | Val-AUC: 0.8004\n",
            "Epoch 7/20 | Val-AUC: 0.3917\n",
            "Epoch 8/20 | Val-AUC: 0.6444\n",
            "Epoch 9/20 | Val-AUC: 0.3810\n",
            "Epoch 10/20 | Val-AUC: 0.4360\n",
            "Epoch 11/20 | Val-AUC: 0.5268\n",
            "Epoch 12/20 | Val-AUC: 0.6026\n",
            "Epoch 13/20 | Val-AUC: 0.7170\n",
            "Epoch 14/20 | Val-AUC: 0.5672\n",
            "Epoch 15/20 | Val-AUC: 0.5670\n",
            "Epoch 16/20 | Val-AUC: 0.6401\n",
            "Epoch 17/20 | Val-AUC: 0.4817\n",
            "Epoch 18/20 | Val-AUC: 0.7010\n",
            "Epoch 19/20 | Val-AUC: 0.5355\n",
            "Epoch 20/20 | Val-AUC: 0.4742\n",
            "\n",
            "Modell 3 Ergebnisse:\n",
            "Beste Val-AUC: 0.8004\n",
            "Test-AUC: 0.5454\n",
            "\n",
            "Training Modell 4/9\n",
            "Epoch 1/20 | Val-AUC: 0.4027\n",
            "Epoch 2/20 | Val-AUC: 0.1970\n",
            "Epoch 3/20 | Val-AUC: 0.6303\n",
            "Epoch 4/20 | Val-AUC: 0.6523\n",
            "Epoch 5/20 | Val-AUC: 0.8220\n",
            "Epoch 6/20 | Val-AUC: 0.7693\n",
            "Epoch 7/20 | Val-AUC: 0.5079\n",
            "Epoch 8/20 | Val-AUC: 0.5904\n",
            "Epoch 9/20 | Val-AUC: 0.7670\n",
            "Epoch 10/20 | Val-AUC: 0.5777\n",
            "Epoch 11/20 | Val-AUC: 0.6158\n",
            "Epoch 12/20 | Val-AUC: 0.7199\n",
            "Epoch 13/20 | Val-AUC: 0.7131\n",
            "Epoch 14/20 | Val-AUC: 0.6597\n",
            "Epoch 15/20 | Val-AUC: 0.6397\n",
            "Epoch 16/20 | Val-AUC: 0.4279\n",
            "Epoch 17/20 | Val-AUC: 0.8491\n",
            "Epoch 18/20 | Val-AUC: 0.5742\n",
            "Epoch 19/20 | Val-AUC: 0.5887\n",
            "Epoch 20/20 | Val-AUC: 0.5811\n",
            "\n",
            "Modell 4 Ergebnisse:\n",
            "Beste Val-AUC: 0.8491\n",
            "Test-AUC: 0.6492\n",
            "\n",
            "Training Modell 5/9\n",
            "Epoch 1/20 | Val-AUC: 0.6307\n",
            "Epoch 2/20 | Val-AUC: 0.7080\n",
            "Epoch 3/20 | Val-AUC: 0.7735\n",
            "Epoch 4/20 | Val-AUC: 0.8119\n",
            "Epoch 5/20 | Val-AUC: 0.6627\n",
            "Epoch 6/20 | Val-AUC: 0.6828\n",
            "Epoch 7/20 | Val-AUC: 0.6510\n",
            "Epoch 8/20 | Val-AUC: 0.4778\n",
            "Epoch 9/20 | Val-AUC: 0.3602\n",
            "Epoch 10/20 | Val-AUC: 0.6302\n",
            "Epoch 11/20 | Val-AUC: 0.4213\n",
            "Epoch 12/20 | Val-AUC: 0.5694\n",
            "Epoch 13/20 | Val-AUC: 0.7926\n",
            "Epoch 14/20 | Val-AUC: 0.5294\n",
            "Epoch 15/20 | Val-AUC: 0.5334\n",
            "Epoch 16/20 | Val-AUC: 0.7701\n",
            "Epoch 17/20 | Val-AUC: 0.5649\n",
            "Epoch 18/20 | Val-AUC: 0.5008\n",
            "Epoch 19/20 | Val-AUC: 0.5796\n",
            "Epoch 20/20 | Val-AUC: 0.6132\n",
            "\n",
            "Modell 5 Ergebnisse:\n",
            "Beste Val-AUC: 0.8119\n",
            "Test-AUC: 0.6798\n",
            "\n",
            "Training Modell 6/9\n",
            "Epoch 1/20 | Val-AUC: 0.7680\n",
            "Epoch 2/20 | Val-AUC: 0.7359\n",
            "Epoch 3/20 | Val-AUC: 0.4523\n",
            "Epoch 4/20 | Val-AUC: 0.5066\n",
            "Epoch 5/20 | Val-AUC: 0.7396\n",
            "Epoch 6/20 | Val-AUC: 0.5730\n",
            "Epoch 7/20 | Val-AUC: 0.4598\n",
            "Epoch 8/20 | Val-AUC: 0.6806\n",
            "Epoch 9/20 | Val-AUC: 0.7315\n",
            "Epoch 10/20 | Val-AUC: 0.6560\n",
            "Epoch 11/20 | Val-AUC: 0.7455\n",
            "Epoch 12/20 | Val-AUC: 0.7128\n",
            "Epoch 13/20 | Val-AUC: 0.4631\n",
            "Epoch 14/20 | Val-AUC: 0.5877\n",
            "Epoch 15/20 | Val-AUC: 0.6107\n",
            "Epoch 16/20 | Val-AUC: 0.6035\n",
            "Epoch 17/20 | Val-AUC: 0.6983\n",
            "Epoch 18/20 | Val-AUC: 0.3185\n",
            "Epoch 19/20 | Val-AUC: 0.5754\n",
            "Epoch 20/20 | Val-AUC: 0.7198\n",
            "\n",
            "Modell 6 Ergebnisse:\n",
            "Beste Val-AUC: 0.7680\n",
            "Test-AUC: 0.6822\n",
            "\n",
            "Training Modell 7/9\n",
            "Epoch 1/20 | Val-AUC: 0.5702\n",
            "Epoch 2/20 | Val-AUC: 0.6860\n",
            "Epoch 3/20 | Val-AUC: 0.3316\n",
            "Epoch 4/20 | Val-AUC: 0.7644\n",
            "Epoch 5/20 | Val-AUC: 0.5095\n",
            "Epoch 6/20 | Val-AUC: 0.7268\n",
            "Epoch 7/20 | Val-AUC: 0.5623\n",
            "Epoch 8/20 | Val-AUC: 0.5136\n",
            "Epoch 9/20 | Val-AUC: 0.6654\n",
            "Epoch 10/20 | Val-AUC: 0.3279\n",
            "Epoch 11/20 | Val-AUC: 0.4797\n",
            "Epoch 12/20 | Val-AUC: 0.6492\n",
            "Epoch 13/20 | Val-AUC: 0.4866\n",
            "Epoch 14/20 | Val-AUC: 0.7969\n",
            "Epoch 15/20 | Val-AUC: 0.4631\n",
            "Epoch 16/20 | Val-AUC: 0.5643\n",
            "Epoch 17/20 | Val-AUC: 0.8002\n",
            "Epoch 18/20 | Val-AUC: 0.4070\n",
            "Epoch 19/20 | Val-AUC: 0.4025\n",
            "Epoch 20/20 | Val-AUC: 0.6728\n",
            "\n",
            "Modell 7 Ergebnisse:\n",
            "Beste Val-AUC: 0.8002\n",
            "Test-AUC: 0.6489\n",
            "\n",
            "Training Modell 8/9\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-670ec69154b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m         )\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mY_pred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1597\u001b[0m             )\n\u001b[1;32m   1598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1600\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset name should not contain `-`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_margin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mmetric_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_eval_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m         _check_call(\n\u001b[0;32m-> 2212\u001b[0;31m             _LIB.XGBoosterEvalOneIter(\n\u001b[0m\u001b[1;32m   2213\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5U8aL1CnC4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}