{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlUHxZy1CpuEky6T9vao/a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascalghanimi/Injury-Prediction-in-Runners/blob/main/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L0NDZyyn2tbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b8c238-67a5-47ce-949b-0a91491678ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.77523982  0.48379555 -0.34174298  1.12482238  4.65573275 -0.30257114\n",
            " -0.36195376  1.13221076  0.88408664  0.98946749 -1.07576228 -0.58780279\n",
            " -0.34515758 -0.21498604 -0.25818757 -0.30257114 -0.36653747 -1.10832632\n",
            " -1.12373205 -1.11938273  0.76147321 -0.58880824 -0.33963599 -0.22015974\n",
            " -0.26519341  3.1128211  -0.36131219  0.94306135  0.88408664  0.88198911\n",
            " -1.08073515 -0.58890474 -0.33382237 -0.21223522 -0.26471133 -0.29617444\n",
            " -0.36131219 -1.10795815 -1.12373205 -1.11942205  0.7667035  -0.5913292\n",
            " -0.33382237 -0.22367068 -0.26509659 -0.29617444  2.42402301  0.57403001\n",
            "  0.88989186  0.9965464   0.78053094  2.39956507  5.70866175 -0.21223522\n",
            " -0.26519341  3.3763886  -0.35067995  1.13636789  0.88989186  0.88771258\n",
            "  0.78584128 -0.58219763 -0.3393889  -0.21762941 -0.25818757 -0.28968273\n",
            "  2.19131074  0.96442407  0.89572629  0.67074481  0.37283858 -0.47040001\n",
            " -0.01179093  0.73505066  1.36358038  0.5749299   0.54093582  1.26319022\n",
            "  2.68987335 -0.05530893  0.11981333  1.16084473  1.93101361  0.58806131\n",
            "  0.31429069  0.54930154  0.          0.          0.          0.47359048\n",
            "  0.31496393  0.506043    0.76168876 -0.87286566  0.44649517  0.43053799\n",
            "  1.64433049 -0.58374345  0.51907295  1.7044102   1.32760601 -0.47118256\n",
            " -0.50544217  1.11651535  1.81048891  0.57307681  0.59895503  0.76791466\n",
            "  0.          0.          0.          0.47149609  0.46378132  0.50441598\n",
            " -0.43179051  0.39885895 -0.32948554  0.03127179 -0.23001359 -0.58356248\n",
            " -0.29617444 -0.14608949  0.18933166 -0.4680759  -0.50378097 -1.03687501\n",
            "  0.4503876   0.30414316  0.3037716   0.29562738  0.          0.\n",
            "  0.          0.61601356  0.44677181  0.79278673 -0.14145291 -0.20789179\n",
            " -0.14145235]\n",
            "[ 0.77523982  0.48379555 -0.34174298  1.12482238  4.65573275 -0.30257114\n",
            " -0.36195376  1.13221076  0.88408664  0.98946749 -1.07576228 -0.58780279\n",
            " -0.34515758 -0.21498604 -0.25818757 -0.30257114 -0.36653747 -1.10832632\n",
            " -1.12373205 -1.11938273  0.76147321 -0.58880824 -0.33963599 -0.22015974\n",
            " -0.26519341  3.1128211  -0.36131219  0.94306135  0.88408664  0.88198911\n",
            " -1.08073515 -0.58890474 -0.33382237 -0.21223522 -0.26471133 -0.29617444\n",
            " -0.36131219 -1.10795815 -1.12373205 -1.11942205  0.7667035  -0.5913292\n",
            " -0.33382237 -0.22367068 -0.26509659 -0.29617444  2.42402301  0.57403001\n",
            "  0.88989186  0.9965464   0.78053094  2.39956507  5.70866175 -0.21223522\n",
            " -0.26519341  3.3763886  -0.35067995  1.13636789  0.88989186  0.88771258\n",
            "  0.78584128 -0.58219763 -0.3393889  -0.21762941 -0.25818757 -0.28968273\n",
            "  2.19131074  0.96442407  0.89572629  0.67074481]\n",
            "[[ 0.37283858 -0.47040001 -0.01179093 ... -0.14145291 -0.20789179\n",
            "  -0.14145235]\n",
            " [ 0.37283858 -0.47040001 -0.04442654 ... -0.14145293 -0.20789189\n",
            "  -0.14145256]\n",
            " [ 0.37283858 -0.47040001 -0.04442654 ... -0.14145293 -0.20789189\n",
            "  -0.14145256]\n",
            " ...\n",
            " [ 1.98934151 -0.90183197  0.37983637 ... -0.14145287 -0.20789189\n",
            "  -0.14145266]\n",
            " [ 1.18109004 -1.33326393  0.33088296 ... -0.14145247 -0.20789195\n",
            "  -0.14145304]\n",
            " [-0.43541289  0.39246391  0.05348029 ... -0.14145298 -0.20789181\n",
            "  -0.14145218]]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 1]\n",
            "139\n"
          ]
        }
      ],
      "source": [
        "# Datenextraktion f√ºr XGBoost\n",
        "import pickle\n",
        "\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "  features = pickle.load(f)\n",
        "\n",
        "with open(\"features_days.pkl\", \"rb\") as f:\n",
        "  features_days = pickle.load(f)\n",
        "\n",
        "with open(\"features_weeks.pkl\", \"rb\") as f:\n",
        "  features_weeks = pickle.load(f)\n",
        "\n",
        "with open(\"features_objective.pkl\", \"rb\") as f:\n",
        "  features_objective = pickle.load(f)\n",
        "\n",
        "with open(\"features_subjective.pkl\", \"rb\") as f:\n",
        "  features_subjective = pickle.load(f)\n",
        "\n",
        "with open(\"labels.pkl\", \"rb\") as f:\n",
        "  labels = pickle.load(f)\n",
        "\n",
        "print(features[0][0]) # greift auf ersten Athleten und erste Reihe zu\n",
        "print(features_days[0][0])\n",
        "print(features_weeks[0])\n",
        "print(labels[0])\n",
        "\n",
        "print(len(features[0][0])) # Anzahl der Features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.vstack([features[athlete_id] for athlete_id in features])\n",
        "X_days = np.vstack([features_days[athlete_id] for athlete_id in features_days])\n",
        "X_weeks = np.vstack([features_weeks[athlete_id] for athlete_id in features_weeks])\n",
        "X_objective = np.vstack([features_objective[athlete_id] for athlete_id in features_objective])\n",
        "X_subjective = np.vstack([features_subjective[athlete_id] for athlete_id in features_subjective])\n",
        "\n",
        "Y = np.hstack([labels[athlete_id] for athlete_id in labels])\n"
      ],
      "metadata": {
        "id": "6HKgTFjTiJRL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_days, X_temp_days, Y_train_days, Y_temp_days = train_test_split(X_days, Y, test_size=0.3, random_state=42)\n",
        "X_val_days, X_test_days, Y_val_days, Y_test_days = train_test_split(X_temp_days, Y_temp_days, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_weeks, X_temp_weeks, Y_train_weeks, Y_temp_weeks = train_test_split(X_weeks, Y, test_size=0.3, random_state=42)\n",
        "X_val_weeks, X_test_weeks, Y_val_weeks, Y_test_weeks = train_test_split(X_temp_weeks, Y_temp_weeks, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_subjective, X_temp_subjective, Y_train_subjective, Y_temp_subjective = train_test_split(X_subjective, Y, test_size=0.3, random_state=42)\n",
        "X_val_subjective, X_test_subjective, Y_val_subjective, Y_test_subjective = train_test_split(X_temp_subjective, Y_temp_subjective, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_objective, X_temp_objective, Y_train_objective, Y_temp_objective = train_test_split(X_objective, Y, test_size=0.3, random_state=42)\n",
        "X_val_objective, X_test_objective, Y_val_objective, Y_test_objective = train_test_split(X_temp_objective, Y_temp_objective, test_size=0.5, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)\n",
        "print(X_train_days.shape, X_val_days.shape, X_test_days.shape)\n",
        "print(X_train_weeks.shape, X_val_weeks.shape, X_test_weeks.shape)\n",
        "print(X_train_subjective.shape, X_val_subjective.shape, X_test_subjective.shape)\n",
        "print(X_train_objective.shape, X_val_objective.shape, X_test_objective.shape)\n",
        "print(Y_train.shape, Y_val.shape, Y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9FNb-mWzJ7L",
        "outputId": "0ada9320-5526-4dcf-8149-509405bd0988"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29876, 139) (6402, 139) (6402, 139)\n",
            "(29876, 70) (6402, 70) (6402, 70)\n",
            "(29876, 69) (6402, 69) (6402, 69)\n",
            "(29876, 48) (6402, 48) (6402, 48)\n",
            "(29876, 91) (6402, 91) (6402, 91)\n",
            "(29876,) (6402,) (6402,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrIPk412lj3J",
        "outputId": "fbe06ada-5842-4165-bb84-f4fd0da331db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_batch(X_train, Y_train, batch_size):\n",
        "    injured_indices = np.where(Y_train == 1)[0]\n",
        "    uninjured_indices = np.where(Y_train == 0)[0]\n",
        "\n",
        "    injured_sample = np.random.choice(injured_indices, size=batch_size // 2, replace=True)\n",
        "    uninjured_sample = np.random.choice(uninjured_indices, size=batch_size // 2, replace=True)\n",
        "\n",
        "    selected_indices = np.concatenate([injured_sample, uninjured_sample])\n",
        "    np.random.shuffle(selected_indices)\n",
        "\n",
        "    X_batch = X_train[selected_indices]\n",
        "    Y_batch = Y_train[selected_indices]\n",
        "\n",
        "    return X_batch, Y_batch"
      ],
      "metadata": {
        "id": "mcJMrz_vtWpa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "# Warnings ausblenden (optional, falls dich andere nicht st√∂ren)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),  # ‚úÖ Kein loguniform mehr\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),  # ‚úÖ Kein suggest_uniform mehr\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 10, log=True),  # ‚úÖ Kein loguniform mehr\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 10, log=True)  # ‚úÖ Kein loguniform mehr\n",
        "    }\n",
        "\n",
        "    X_batch, Y_batch = get_training_batch(X_train, Y_train, 2048)\n",
        "\n",
        "    # Modell trainieren\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "    model.fit(X_batch, Y_batch, eval_set=[(X_val, Y_val)], verbose=False)\n",
        "\n",
        "    # AUC messen\n",
        "    Y_pred = model.predict_proba(X_val)[:, 1]\n",
        "    return roc_auc_score(Y_val, Y_pred)\n",
        "\n",
        "# üî• Optuna-Optimierung starten\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)  # 50 Versuche f√ºr Optimierung\n",
        "\n",
        "# Beste Hyperparameter ausgeben\n",
        "print(\"Beste Hyperparameter:\", study.best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scetv7Oomgmi",
        "outputId": "beb8987b-9517-4ea1-d4c3-f2d0fb71eaa9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-03 11:22:41,298] A new study created in memory with name: no-name-e780572b-93b1-46ec-8ee2-b5e1dc8416f1\n",
            "[I 2025-03-03 11:23:31,050] Trial 0 finished with value: 0.7290542401284372 and parameters: {'learning_rate': 0.009291855781281052, 'max_depth': 10, 'subsample': 0.7171060944154687, 'colsample_bytree': 0.9960668873160612, 'n_estimators': 331, 'reg_lambda': 0.5854705051833753, 'reg_alpha': 1.377237424934184}. Best is trial 0 with value: 0.7290542401284372.\n",
            "[I 2025-03-03 11:23:48,049] Trial 1 finished with value: 0.6950250097167779 and parameters: {'learning_rate': 0.05117534576350498, 'max_depth': 10, 'subsample': 0.8446403325890988, 'colsample_bytree': 0.9863734621167967, 'n_estimators': 298, 'reg_lambda': 0.010938056672951791, 'reg_alpha': 0.26609114858651844}. Best is trial 0 with value: 0.7290542401284372.\n",
            "[I 2025-03-03 11:24:01,137] Trial 2 finished with value: 0.7191616813248412 and parameters: {'learning_rate': 0.012620307651969039, 'max_depth': 7, 'subsample': 0.8364043596003488, 'colsample_bytree': 0.6661116690677831, 'n_estimators': 241, 'reg_lambda': 0.06776045075498004, 'reg_alpha': 2.20091868288791}. Best is trial 0 with value: 0.7290542401284372.\n",
            "[I 2025-03-03 11:24:06,834] Trial 3 finished with value: 0.6979918007972641 and parameters: {'learning_rate': 0.0018097316023557779, 'max_depth': 3, 'subsample': 0.9167947985752469, 'colsample_bytree': 0.512229879582313, 'n_estimators': 334, 'reg_lambda': 4.037570671987895, 'reg_alpha': 2.86860489841708}. Best is trial 0 with value: 0.7290542401284372.\n",
            "[I 2025-03-03 11:24:39,921] Trial 4 finished with value: 0.7255854969033264 and parameters: {'learning_rate': 0.009080636431432268, 'max_depth': 7, 'subsample': 0.8563385801379324, 'colsample_bytree': 0.5240910951468161, 'n_estimators': 786, 'reg_lambda': 0.05745627778505576, 'reg_alpha': 0.283256106017249}. Best is trial 0 with value: 0.7290542401284372.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beste Hyperparameter: {'learning_rate': 0.009291855781281052, 'max_depth': 10, 'subsample': 0.7171060944154687, 'colsample_bytree': 0.9960668873160612, 'n_estimators': 331, 'reg_lambda': 0.5854705051833753, 'reg_alpha': 1.377237424934184}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "def train (X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
        "\n",
        "  best_params = study.best_params\n",
        "  params = best_params\n",
        "\n",
        "  num_models = 9\n",
        "  models = []\n",
        "  batch_size = 2048\n",
        "\n",
        "  for model_idx in range(num_models):\n",
        "    X_batch, Y_batch = get_training_batch(X_train, Y_train, batch_size)\n",
        "\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "    model.fit(X_batch, Y_batch, eval_set=[(X_val, Y_val)], verbose=False)\n",
        "    Y_preds_test = model.predict_proba(X_test)[:, 1]\n",
        "    test_auc = roc_auc_score(Y_test, Y_preds_test)\n",
        "\n",
        "    print(f\"\\nModell {model_idx + 1} Ergebnisse:\")\n",
        "    print(f\"Test-AUC: {test_auc:.4f}\")\n",
        "    models.append(model)\n",
        "\n",
        "  calibrated_models = [\n",
        "      CalibratedClassifierCV(m, method='sigmoid', cv=\"prefit\").fit(X_val, Y_val) for m in models\n",
        "  ]\n",
        "\n",
        "\n",
        "  # Ensemble-AUC auf Wahrscheinlichkeiten\n",
        "  def ensemble_predict(models, X):\n",
        "    test_probas = np.stack([m.predict_proba(X)[:, 1] for m in models])\n",
        "    return np.mean(test_probas, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "  Y_proba_test = ensemble_predict(calibrated_models, X_test)\n",
        "  test_auc = roc_auc_score(Y_test, Y_proba_test)\n",
        "\n",
        "  print(f\"Test-AUC: {test_auc:.4f}\")\n",
        "\n",
        "  return calibrated_models, test_auc"
      ],
      "metadata": {
        "id": "XrgTwWA9DXKA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training mit allen Featuren\n",
        "xgb_models, _ = train(X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMa7-HHQbsx_",
        "outputId": "5775f733-9509-4689-a2b7-e1fe8bddf7e6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modell 1 Ergebnisse:\n",
            "Test-AUC: 0.6988\n",
            "\n",
            "Modell 2 Ergebnisse:\n",
            "Test-AUC: 0.7053\n",
            "\n",
            "Modell 3 Ergebnisse:\n",
            "Test-AUC: 0.7030\n",
            "\n",
            "Modell 4 Ergebnisse:\n",
            "Test-AUC: 0.7075\n",
            "\n",
            "Modell 5 Ergebnisse:\n",
            "Test-AUC: 0.7064\n",
            "\n",
            "Modell 6 Ergebnisse:\n",
            "Test-AUC: 0.7076\n",
            "\n",
            "Modell 7 Ergebnisse:\n",
            "Test-AUC: 0.6996\n",
            "\n",
            "Modell 8 Ergebnisse:\n",
            "Test-AUC: 0.6976\n",
            "\n",
            "Modell 9 Ergebnisse:\n",
            "Test-AUC: 0.6885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test-AUC: 0.7159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training mit den Tagesdaten\n",
        "xgb_models_days, _ = train(X_train_days, Y_train_days, X_val_days, Y_val_days, X_test_days, Y_test_days)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S9TY7UdcES-",
        "outputId": "6eef0920-ce35-460c-c5c0-94f60c73e4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modell 1 Ergebnisse:\n",
            "Test-AUC: 0.6996\n",
            "\n",
            "Modell 2 Ergebnisse:\n",
            "Test-AUC: 0.6886\n",
            "\n",
            "Modell 3 Ergebnisse:\n",
            "Test-AUC: 0.6997\n",
            "\n",
            "Modell 4 Ergebnisse:\n",
            "Test-AUC: 0.6771\n",
            "\n",
            "Modell 5 Ergebnisse:\n",
            "Test-AUC: 0.7034\n",
            "\n",
            "Modell 6 Ergebnisse:\n",
            "Test-AUC: 0.7042\n",
            "\n",
            "Modell 7 Ergebnisse:\n",
            "Test-AUC: 0.7076\n",
            "\n",
            "Modell 8 Ergebnisse:\n",
            "Test-AUC: 0.7098\n",
            "\n",
            "Modell 9 Ergebnisse:\n",
            "Test-AUC: 0.6816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test-AUC des Ensembles: 0.7148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training mit den Wochendaten\n",
        "xgb_models_weeks, _ = train(X_train_weeks, Y_train_weeks, X_val_weeks, Y_val_weeks, X_test_weeks, Y_test_weeks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEGwEqsFcQV0",
        "outputId": "74e1b6de-c1a9-48c5-e3a4-a374b4940e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modell 1 Ergebnisse:\n",
            "Test-AUC: 0.6731\n",
            "\n",
            "Modell 2 Ergebnisse:\n",
            "Test-AUC: 0.6876\n",
            "\n",
            "Modell 3 Ergebnisse:\n",
            "Test-AUC: 0.6762\n",
            "\n",
            "Modell 4 Ergebnisse:\n",
            "Test-AUC: 0.7017\n",
            "\n",
            "Modell 5 Ergebnisse:\n",
            "Test-AUC: 0.6612\n",
            "\n",
            "Modell 6 Ergebnisse:\n",
            "Test-AUC: 0.6668\n",
            "\n",
            "Modell 7 Ergebnisse:\n",
            "Test-AUC: 0.7078\n",
            "\n",
            "Modell 8 Ergebnisse:\n",
            "Test-AUC: 0.6836\n",
            "\n",
            "Modell 9 Ergebnisse:\n",
            "Test-AUC: 0.6911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test-AUC des Ensembles: 0.6995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training mit den objektiven Daten\n",
        "xgb_models_objective, _ = train(X_train_objective, Y_train_objective, X_val_objective, Y_val_objective, X_test_objective, Y_test_objective)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdwti1nKcYSt",
        "outputId": "7baf7a09-b771-4c2e-b736-a5e94d421c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modell 1 Ergebnisse:\n",
            "Test-AUC: 0.6893\n",
            "\n",
            "Modell 2 Ergebnisse:\n",
            "Test-AUC: 0.7130\n",
            "\n",
            "Modell 3 Ergebnisse:\n",
            "Test-AUC: 0.6800\n",
            "\n",
            "Modell 4 Ergebnisse:\n",
            "Test-AUC: 0.7061\n",
            "\n",
            "Modell 5 Ergebnisse:\n",
            "Test-AUC: 0.7177\n",
            "\n",
            "Modell 6 Ergebnisse:\n",
            "Test-AUC: 0.6869\n",
            "\n",
            "Modell 7 Ergebnisse:\n",
            "Test-AUC: 0.7009\n",
            "\n",
            "Modell 8 Ergebnisse:\n",
            "Test-AUC: 0.7077\n",
            "\n",
            "Modell 9 Ergebnisse:\n",
            "Test-AUC: 0.6983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test-AUC des Ensembles: 0.7189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training mit den subjektiven Daten\n",
        "xgb_models_subjective, _ = train(X_train_subjective, Y_train_subjective, X_val_subjective, Y_val_subjective, X_test_subjective, Y_test_subjective)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kxvcnCVclj5",
        "outputId": "99bbff71-680f-415a-d735-c483b96746d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modell 1 Ergebnisse:\n",
            "Test-AUC: 0.6598\n",
            "\n",
            "Modell 2 Ergebnisse:\n",
            "Test-AUC: 0.6324\n",
            "\n",
            "Modell 3 Ergebnisse:\n",
            "Test-AUC: 0.6615\n",
            "\n",
            "Modell 4 Ergebnisse:\n",
            "Test-AUC: 0.6523\n",
            "\n",
            "Modell 5 Ergebnisse:\n",
            "Test-AUC: 0.6760\n",
            "\n",
            "Modell 6 Ergebnisse:\n",
            "Test-AUC: 0.6493\n",
            "\n",
            "Modell 7 Ergebnisse:\n",
            "Test-AUC: 0.6775\n",
            "\n",
            "Modell 8 Ergebnisse:\n",
            "Test-AUC: 0.6500\n",
            "\n",
            "Modell 9 Ergebnisse:\n",
            "Test-AUC: 0.6725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test-AUC des Ensembles: 0.6823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "amount_of_trainings = 2\n",
        "all_auc_scores = []\n",
        "auc_scores_days = []\n",
        "auc_scores_weeks = []\n",
        "auc_scores_objective = []\n",
        "auc_scores_subjective = []\n",
        "\n",
        "def calculate_average_auc_over_10_rounds(train_fn, auc_scores_array):\n",
        "  for training in range(amount_of_trainings):\n",
        "    _, auc = train_fn()\n",
        "    auc_scores_array.append(auc)\n",
        "  mean_auc_score = np.mean(auc_scores_array)\n",
        "  std_auc_score = np.std(auc_scores_array)\n",
        "  print(f\"Mean AUC Score: {mean_auc_score}\")\n",
        "  print(f\"Standard Deviation of AUC Scores: {std_auc_score}\")\n",
        "\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train, Y_train, X_val, Y_val, X_test, Y_test), all_auc_scores)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_days, Y_train_days, X_val_days, Y_val_days, X_test_days, Y_test_days), auc_scores_days)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_weeks, Y_train_weeks, X_val_weeks, Y_val_weeks, X_test_weeks, Y_test_weeks), auc_scores_weeks)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_objective, Y_train_objective, X_val_objective, Y_val_objective, X_test_objective, Y_test_objective), auc_scores_objective)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_subjective, Y_train_subjective, X_val_subjective, Y_val_subjective, X_test_subjective, Y_test_subjective), auc_scores_subjective)"
      ],
      "metadata": {
        "id": "Njf4n5xxuhpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Stil f√ºr moderne Diagramme setzen\n",
        "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
        "\n",
        "# Boxplot f√ºr alle Feature-Sets\n",
        "plt.figure(figsize=(10, 6))\n",
        "box = plt.boxplot(\n",
        "    [all_auc_scores, auc_scores_days, auc_scores_weeks, auc_scores_objective, auc_scores_subjective],\n",
        "    labels=[\"All Features\", \"Days\", \"Weeks\", \"Objective\", \"Subjective\"],\n",
        "    patch_artist=True,\n",
        "    boxprops=dict(facecolor=\"lightblue\", color=\"black\"),\n",
        "    medianprops=dict(color=\"darkred\", linewidth=2),\n",
        "    whiskerprops=dict(color=\"black\", linewidth=1.5),\n",
        "    capprops=dict(color=\"black\", linewidth=1.5)\n",
        ")\n",
        "plt.ylabel(\"AUC Score\", fontsize=12, fontweight=\"bold\")\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.title(\"Vergleich der AUC Scores √ºber verschiedene Feature-Sets\", fontsize=14, fontweight=\"bold\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "# Mittelwerte berechnen\n",
        "mean_auc_scores = {\n",
        "    \"All Features\": np.mean(all_auc_scores),\n",
        "    \"Days\": np.mean(auc_scores_days),\n",
        "    \"Weeks\": np.mean(auc_scores_weeks),\n",
        "    \"Objective\": np.mean(auc_scores_objective),\n",
        "    \"Subjective\": np.mean(auc_scores_subjective),\n",
        "}\n",
        "\n",
        "# Balkendiagramm f√ºr Mittelwerte der AUC-Scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(mean_auc_scores.keys(), mean_auc_scores.values(), color=[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"], alpha=0.85, edgecolor=\"black\", linewidth=1.2)\n",
        "plt.ylabel(\"Mean AUC Score\", fontsize=12, fontweight=\"bold\")\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.title(\"Mittlere AUC Scores f√ºr verschiedene Feature-Sets\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylim(min(mean_auc_scores.values()) - 0.01, max(mean_auc_scores.values()) + 0.01)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "# Werte √ºber den Balken anzeigen\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.002, f\"{yval:.4f}\", ha=\"center\", fontsize=11, fontweight=\"bold\", color=\"black\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LXRxYWRu_h8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(xgb_models, 'xgb_models.pkl')\n",
        "joblib.dump(xgb_models_days, 'xgb_models_days.pkl')\n",
        "joblib.dump(xgb_models_weeks, 'xgb_models_weeks.pkl')\n",
        "joblib.dump(xgb_models_objective, 'xgb_models_objective.pkl')\n",
        "joblib.dump(xgb_models_subjective, 'xgb_models_subjective.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu0TUcZ3BW0K",
        "outputId": "28f4f5d0-1f79-440a-9b98-d2e708fed9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xgb_models_subjective.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}