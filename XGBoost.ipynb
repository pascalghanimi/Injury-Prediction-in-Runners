{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO93CoyeOLQveo7bIeItpIt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascalghanimi/Injury-Prediction-in-Runners/blob/main/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0NDZyyn2tbh"
      },
      "outputs": [],
      "source": [
        "# Data extraction for XGBoost\n",
        "import pickle\n",
        "\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "  features = pickle.load(f)\n",
        "\n",
        "with open(\"features_days.pkl\", \"rb\") as f:\n",
        "  features_days = pickle.load(f)\n",
        "\n",
        "with open(\"features_weeks.pkl\", \"rb\") as f:\n",
        "  features_weeks = pickle.load(f)\n",
        "\n",
        "with open(\"features_objective.pkl\", \"rb\") as f:\n",
        "  features_objective = pickle.load(f)\n",
        "\n",
        "with open(\"features_subjective.pkl\", \"rb\") as f:\n",
        "  features_subjective = pickle.load(f)\n",
        "\n",
        "with open(\"labels.pkl\", \"rb\") as f:\n",
        "  labels = pickle.load(f)\n",
        "\n",
        "print(features[0][0]) # first athlete first row\n",
        "print(features_days[0][0])\n",
        "print(features_weeks[0])\n",
        "print(labels[0])\n",
        "\n",
        "print(len(features[0][0])) # amount of features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.vstack([features[athlete_id] for athlete_id in features])\n",
        "X_days = np.vstack([features_days[athlete_id] for athlete_id in features_days])\n",
        "X_weeks = np.vstack([features_weeks[athlete_id] for athlete_id in features_weeks])\n",
        "X_objective = np.vstack([features_objective[athlete_id] for athlete_id in features_objective])\n",
        "X_subjective = np.vstack([features_subjective[athlete_id] for athlete_id in features_subjective])\n",
        "\n",
        "Y = np.hstack([labels[athlete_id] for athlete_id in labels])\n"
      ],
      "metadata": {
        "id": "6HKgTFjTiJRL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_days, X_temp_days, Y_train_days, Y_temp_days = train_test_split(X_days, Y, test_size=0.3, random_state=42)\n",
        "X_val_days, X_test_days, Y_val_days, Y_test_days = train_test_split(X_temp_days, Y_temp_days, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_weeks, X_temp_weeks, Y_train_weeks, Y_temp_weeks = train_test_split(X_weeks, Y, test_size=0.3, random_state=42)\n",
        "X_val_weeks, X_test_weeks, Y_val_weeks, Y_test_weeks = train_test_split(X_temp_weeks, Y_temp_weeks, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_subjective, X_temp_subjective, Y_train_subjective, Y_temp_subjective = train_test_split(X_subjective, Y, test_size=0.3, random_state=42)\n",
        "X_val_subjective, X_test_subjective, Y_val_subjective, Y_test_subjective = train_test_split(X_temp_subjective, Y_temp_subjective, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train_objective, X_temp_objective, Y_train_objective, Y_temp_objective = train_test_split(X_objective, Y, test_size=0.3, random_state=42)\n",
        "X_val_objective, X_test_objective, Y_val_objective, Y_test_objective = train_test_split(X_temp_objective, Y_temp_objective, test_size=0.5, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)\n",
        "print(X_train_days.shape, X_val_days.shape, X_test_days.shape)\n",
        "print(X_train_weeks.shape, X_val_weeks.shape, X_test_weeks.shape)\n",
        "print(X_train_subjective.shape, X_val_subjective.shape, X_test_subjective.shape)\n",
        "print(X_train_objective.shape, X_val_objective.shape, X_test_objective.shape)\n",
        "print(Y_train.shape, Y_val.shape, Y_test.shape)\n"
      ],
      "metadata": {
        "id": "X9FNb-mWzJ7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "NrIPk412lj3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_batch(X_train, Y_train, batch_size):\n",
        "    injured_indices = np.where(Y_train == 1)[0]\n",
        "    uninjured_indices = np.where(Y_train == 0)[0]\n",
        "\n",
        "    injured_sample = np.random.choice(injured_indices, size=batch_size // 2, replace=True)\n",
        "    uninjured_sample = np.random.choice(uninjured_indices, size=batch_size // 2, replace=True)\n",
        "\n",
        "    selected_indices = np.concatenate([injured_sample, uninjured_sample])\n",
        "    np.random.shuffle(selected_indices)\n",
        "\n",
        "    X_batch = X_train[selected_indices]\n",
        "    Y_batch = Y_train[selected_indices]\n",
        "\n",
        "    return X_batch, Y_batch"
      ],
      "metadata": {
        "id": "mcJMrz_vtWpa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 10, log=True),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 10, log=True)\n",
        "    }\n",
        "\n",
        "    X_batch, Y_batch = get_training_batch(X_train, Y_train, 2048)\n",
        "\n",
        "    # Modell trainieren\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "    model.fit(X_batch, Y_batch, eval_set=[(X_val, Y_val)], verbose=False)\n",
        "\n",
        "    # AUC messen\n",
        "    Y_pred = model.predict_proba(X_val)[:, 1]\n",
        "    return roc_auc_score(Y_val, Y_pred)\n",
        "\n",
        "# ðŸ”¥ Optuna-Optimierung starten\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100) # 100 trials\n",
        "\n",
        "# Print best hyperparameters\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n"
      ],
      "metadata": {
        "id": "scetv7Oomgmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "def train (X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
        "\n",
        "  best_params = study.best_params\n",
        "  params = best_params\n",
        "\n",
        "  num_models = 9\n",
        "  models = []\n",
        "  batch_size = 2048\n",
        "\n",
        "  for model_idx in range(num_models):\n",
        "    X_batch, Y_batch = get_training_batch(X_train, Y_train, batch_size)\n",
        "\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "    model.fit(X_batch, Y_batch, eval_set=[(X_val, Y_val)], verbose=False)\n",
        "    Y_preds_test = model.predict_proba(X_test)[:, 1]\n",
        "    test_auc = roc_auc_score(Y_test, Y_preds_test)\n",
        "\n",
        "    print(f\"\\nModell {model_idx + 1} Ergebnisse:\")\n",
        "    print(f\"Test-AUC: {test_auc:.4f}\")\n",
        "    models.append(model)\n",
        "\n",
        "  calibrated_models = [\n",
        "      CalibratedClassifierCV(m, method='sigmoid', cv=\"prefit\").fit(X_val, Y_val) for m in models\n",
        "  ]\n",
        "\n",
        "\n",
        "  # Ensemble-AUC\n",
        "  def ensemble_predict(models, X):\n",
        "    test_probas = np.stack([m.predict_proba(X)[:, 1] for m in models])\n",
        "    return np.mean(test_probas, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "  Y_proba_test = ensemble_predict(calibrated_models, X_test)\n",
        "  test_auc = roc_auc_score(Y_test, Y_proba_test)\n",
        "\n",
        "  print(f\"Test-AUC: {test_auc:.4f}\")\n",
        "\n",
        "  return calibrated_models, test_auc"
      ],
      "metadata": {
        "id": "XrgTwWA9DXKA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with all features (weeks and days combined)\n",
        "xgb_models, _ = train(X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ],
      "metadata": {
        "id": "LMa7-HHQbsx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with days data\n",
        "xgb_models_days, _ = train(X_train_days, Y_train_days, X_val_days, Y_val_days, X_test_days, Y_test_days)"
      ],
      "metadata": {
        "id": "8S9TY7UdcES-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with weeks data\n",
        "xgb_models_weeks, _ = train(X_train_weeks, Y_train_weeks, X_val_weeks, Y_val_weeks, X_test_weeks, Y_test_weeks)"
      ],
      "metadata": {
        "id": "zEGwEqsFcQV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with objective data\n",
        "xgb_models_objective, _ = train(X_train_objective, Y_train_objective, X_val_objective, Y_val_objective, X_test_objective, Y_test_objective)"
      ],
      "metadata": {
        "id": "Sdwti1nKcYSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with subjective data\n",
        "xgb_models_subjective, _ = train(X_train_subjective, Y_train_subjective, X_val_subjective, Y_val_subjective, X_test_subjective, Y_test_subjective)"
      ],
      "metadata": {
        "id": "1kxvcnCVclj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amount_of_trainings = 10\n",
        "all_auc_scores = []\n",
        "auc_scores_days = []\n",
        "auc_scores_weeks = []\n",
        "auc_scores_objective = []\n",
        "auc_scores_subjective = []\n",
        "\n",
        "def calculate_average_auc_over_10_rounds(train_fn, auc_scores_array):\n",
        "  for training in range(amount_of_trainings):\n",
        "    _, auc = train_fn()\n",
        "    auc_scores_array.append(auc)\n",
        "  mean_auc_score = np.mean(auc_scores_array)\n",
        "  std_auc_score = np.std(auc_scores_array)\n",
        "  print(f\"Mean AUC Score: {mean_auc_score}\")\n",
        "  print(f\"Standard Deviation of AUC Scores: {std_auc_score}\")\n",
        "\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train, Y_train, X_val, Y_val, X_test, Y_test), all_auc_scores)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_days, Y_train_days, X_val_days, Y_val_days, X_test_days, Y_test_days), auc_scores_days)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_weeks, Y_train_weeks, X_val_weeks, Y_val_weeks, X_test_weeks, Y_test_weeks), auc_scores_weeks)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_objective, Y_train_objective, X_val_objective, Y_val_objective, X_test_objective, Y_test_objective), auc_scores_objective)\n",
        "calculate_average_auc_over_10_rounds(lambda: train(X_train_subjective, Y_train_subjective, X_val_subjective, Y_val_subjective, X_test_subjective, Y_test_subjective), auc_scores_subjective)"
      ],
      "metadata": {
        "id": "Njf4n5xxuhpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
        "\n",
        "# Boxplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "box = plt.boxplot(\n",
        "    [all_auc_scores, auc_scores_days, auc_scores_weeks, auc_scores_objective, auc_scores_subjective],\n",
        "    labels=[\"All Features\", \"Days\", \"Weeks\", \"Objective\", \"Subjective\"],\n",
        "    patch_artist=True,\n",
        "    boxprops=dict(facecolor=\"lightblue\", color=\"black\"),\n",
        "    medianprops=dict(color=\"darkred\", linewidth=2),\n",
        "    whiskerprops=dict(color=\"black\", linewidth=1.5),\n",
        "    capprops=dict(color=\"black\", linewidth=1.5)\n",
        ")\n",
        "plt.ylabel(\"AUC Score\", fontsize=12, fontweight=\"bold\")\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.title(\"Vergleich der AUC Scores Ã¼ber verschiedene Feature-Sets\", fontsize=14, fontweight=\"bold\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "# Mean\n",
        "mean_auc_scores = {\n",
        "    \"All Features\": np.mean(all_auc_scores),\n",
        "    \"Days\": np.mean(auc_scores_days),\n",
        "    \"Weeks\": np.mean(auc_scores_weeks),\n",
        "    \"Objective\": np.mean(auc_scores_objective),\n",
        "    \"Subjective\": np.mean(auc_scores_subjective),\n",
        "}\n",
        "\n",
        "# Diagrams\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(mean_auc_scores.keys(), mean_auc_scores.values(), color=[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"], alpha=0.85, edgecolor=\"black\", linewidth=1.2)\n",
        "plt.ylabel(\"Mean AUC Score\", fontsize=12, fontweight=\"bold\")\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.title(\"Mittlere AUC Scores fÃ¼r verschiedene Feature-Sets\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylim(min(mean_auc_scores.values()) - 0.01, max(mean_auc_scores.values()) + 0.01)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.002, f\"{yval:.4f}\", ha=\"center\", fontsize=11, fontweight=\"bold\", color=\"black\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LXRxYWRu_h8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single model export (only all features since it has the best probabilities overall)\n",
        "joblib.dump(xgb_models, 'xgb_models.pkl')"
      ],
      "metadata": {
        "id": "Ec3aQ8m-VY-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model export for Ensemble prediction later\n",
        "import joblib\n",
        "\n",
        "joblib.dump(xgb_models, 'xgb_models.pkl')\n",
        "joblib.dump(xgb_models_days, 'xgb_models_days.pkl')\n",
        "joblib.dump(xgb_models_weeks, 'xgb_models_weeks.pkl')\n",
        "joblib.dump(xgb_models_objective, 'xgb_models_objective.pkl')\n",
        "joblib.dump(xgb_models_subjective, 'xgb_models_subjective.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu0TUcZ3BW0K",
        "outputId": "28f4f5d0-1f79-440a-9b98-d2e708fed9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xgb_models_subjective.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}